{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "\n",
    "\n",
    "class SOMToolBox_Parse:\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "    \n",
    "    def read_weight_file(self,):\n",
    "        df = pd.DataFrame()\n",
    "        if self.filename[-3:len(self.filename)] == '.gz':\n",
    "            with gzip.open(self.filename, 'rb') as file:\n",
    "                df, vec_dim, xdim, ydim = self._read_vector_file_to_df(df, file)\n",
    "        else:\n",
    "            with open(self.filename, 'rb') as file:\n",
    "                df, vec_dim, xdim, ydim = self._read_vector_file_to_df(df, file)\n",
    "\n",
    "        file.close()            \n",
    "        return df.astype('float64'), vec_dim, xdim, ydim\n",
    "\n",
    "\n",
    "    def _read_vector_file_to_df(self, df, file):\n",
    "        xdim, ydim, vec_dim, position = 0, 0, 0, 0\n",
    "        for byte in file:\n",
    "            line = byte.decode('UTF-8')\n",
    "            if line.startswith('$'):\n",
    "                xdim, ydim, vec_dim = self._parse_vector_file_metadata(line, xdim, ydim, vec_dim)\n",
    "                if xdim > 0 and ydim > 0 and len(df.columns) == 0:\n",
    "                    df = pd.DataFrame(index=range(0, ydim * xdim), columns=range(0, vec_dim))\n",
    "            else:\n",
    "                if len(df.columns) == 0 or vec_dim == 0:\n",
    "                    raise ValueError('Weight file has no correct Dimensional information.')\n",
    "                position = self._parse_weight_file_data(line, position, vec_dim, df)\n",
    "        return df, vec_dim, xdim, ydim\n",
    "\n",
    "\n",
    "    def _parse_weight_file_data(self, line, position, vec_dim, df):\n",
    "        splitted=line.split(' ')\n",
    "        try:\n",
    "            df.values[position] = list(np.array(splitted[0:vec_dim]).astype(float))\n",
    "            position += 1\n",
    "        except: raise ValueError('The input-vector file does not match its unit-dimension.') \n",
    "        return  position\n",
    "\n",
    "\n",
    "    def _parse_vector_file_metadata(self, line, xdim, ydim, vec_dim):\n",
    "        splitted = line.split(' ')\n",
    "        if splitted[0] == '$XDIM':      xdim = int(splitted[1])\n",
    "        elif splitted[0] == '$YDIM':    ydim = int(splitted[1])\n",
    "        elif splitted[0] == '$VEC_DIM': vec_dim = int(splitted[1])\n",
    "        return xdim, ydim, vec_dim \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report - Clustering of SOM\n",
    "\n",
    "## Group G2\n",
    "Aron Ingruber (01634059), Dominik Veselý (01633647)\n",
    "\n",
    "Link to public repository: [https://github.com/aroningruber/SOS-Exercise3-Group-G2](https://github.com/aroningruber/SOS-Exercise3-Group-G2)\n",
    "\n",
    "## Implementation\n",
    "We extended the class `SomViz` in the following cell with additional functions that add clustering of the SOM visualizations. For these visualizations, the weight vectors of those SOM units that are the best-matching unit for at least one input vector (i.e. interpolating units are omitted) are clustered. The SOM is then visualized with the units colored according to the cluster they belong to. Interpolating units are not colored and are thus left black.\n",
    "\n",
    "As per requirement, four clustering methods are provided, namely k-means, as well as agglomerative clustering with the three linkage criterions \"single\", \"complete\" and \"WARD\". All of our implemented methods take the same arguments:\n",
    "\n",
    "+ `n_clusters`: The number of clusters (integer).\n",
    "+ `idata`: The input vectors (the data the SOM should be mapped to)\n",
    "+ `title`: The title for the produced visualization.\n",
    "\n",
    "The k-means implementation additionally accepts a `random_state` argument to ensure determinism.\n",
    "\n",
    "### K-Means\n",
    "\n",
    "The K-Means clustering algorithm minimizes the within-cluster sum-of-squares. Each data point is assigned to the cluster with the nearest mean (also referred to as cluster centroid), thus partitioning the data space into Voronoi cells. k denotes the number of clusters and determines the number of centroids that are created (usually by randomly selecting k data points) in the first stage of the algorithm. These centroids are iteratively adapted by clustering the data and shifting the centroids to the centers of gravity within each cluster. This iterative process stops when the means do not change anymore.\n",
    "\n",
    "Disadvantages:\n",
    "+ Depends on initially selected centroids.\n",
    "+ Noise has a lot of influence on clustering results.\n",
    "\n",
    "We use `scikit-learn`'s [implementation of the k-means algorithm](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).\n",
    "\n",
    "The method signature is `kmeans(self, n_clusters: int, idata=[], title=\"\", random_state=42)`.\n",
    "\n",
    "### Hierarchical Clustering (Agglomerative)\n",
    "\n",
    "In hierarchical agglomerative clustering, all data points are first assigned to their own cluster. These clusters are then iteratively merged (which can be used to produce a dendogram as a by-product). There are different criteria that can be used for deciding, which clusters to merge. As already mentioned, we implement three of them:\n",
    "\n",
    "+ Single Linkage: minimizes the distance between the closest vectors of pairs of clusters.\n",
    "+ Complete Linkage (or Maximum Linkage): minimizes the maximum distance between the closest vectors of pairs of clusters.\n",
    "+ WARD: minimizes the sum-of-squares within each cluster (thus making it a hierarchical variant of the  k-means algorithm)\n",
    "\n",
    "We use `scipy`'s [implementation of the hierarchical clustering](https://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html). This requires the computation of the pairwise distances between vectors, for which we also use `scipy`'s [implementation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html).\n",
    "\n",
    "The method signatures are:\n",
    "+ `single_linkage(self, n_clusters: int, idata=[], title=\"\")`\n",
    "+ `complete_linkage(self, n_clusters: int, idata=[], title=\"\")`\n",
    "+ `ward_linkage(self, n_clusters: int, idata=[], title=\"\")`\n",
    "\n",
    "### Helper Methods\n",
    "\n",
    "All four clustering methods above call our `plot_clusters(self, n_clusters: int, labels, mask, title=\"\")` method. This method is essentially an adaptation of the existing `plot()` method. It also uses `plotly`'s [Heatmap](https://plotly.github.io/plotly.py-docs/generated/plotly.graph_objects.Heatmap.html), but adds a grid to it, by creating gaps between units. It also colors the background (and thus interpolating, empty units, which are not part of the clustering) in black. The color scale to use depends on the number of clusters. Since the heatmap uses continuous color scales, the individual clusters can be difficult to distinguish visually when too many clusters are created. However, one can still hover over each unit to see the label of the respective cluster it belongs to.\n",
    "\n",
    "We have also created the helper functions `get_mask(self, idata=[])` and `get_hist(self, idata=[])`. The latter is code extracted from the existing Hit Histogram visualization (`hithist()`). The former uses `get_hist()` to create a boolean mask, which separates interpolating units and those that are BMU for at least one input vector. This mask is used in the clustering methods to only cluster non-interpolating units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.container { width:100% !important; }</style>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial import distance_matrix, distance\n",
    "from ipywidgets import Layout, HBox, Box, widgets, interact\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn import cluster\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\")) \n",
    "\n",
    "class SomViz:\n",
    "    \n",
    "    def __init__(self, weights=[], m=None, n=None):\n",
    "        self.weights = weights\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "    \n",
    "    def get_hist(self, idata=[]):\n",
    "        hist = [0] *self.n *self.m\n",
    "        for v in idata: \n",
    "            position =np.argmin(np.sqrt(np.sum(np.power(self.weights - v, 2), axis=1)))\n",
    "            hist[position] += 1\n",
    "        return np.array(hist)\n",
    "    \n",
    "    def get_mask(self, idata=[]):\n",
    "        hist = self.get_hist(idata)\n",
    "        mask = hist > 0\n",
    "        return mask\n",
    "\n",
    "    def umatrix(self, som_map=None, color=\"Viridis\", interp = \"best\", title=\"\"):\n",
    "        um =np.zeros((self.m *self.n, 1))\n",
    "        neuron_locs = list()\n",
    "        for i in range(self.m):\n",
    "            for j in range(self.n):\n",
    "                neuron_locs.append(np.array([i, j]))\n",
    "        neuron_distmat = distance_matrix(neuron_locs,neuron_locs)\n",
    "\n",
    "        for i in range(self.m * self.n):\n",
    "            neighbor_idxs = neuron_distmat[i] <= 1\n",
    "            neighbor_weights = self.weights[neighbor_idxs]\n",
    "            um[i] = distance_matrix(np.expand_dims(self.weights[i], 0), neighbor_weights).mean()\n",
    "\n",
    "        if som_map==None: return self.plot(um.reshape(self.m,self.n), color=color, interp=interp, title=title)    \n",
    "        else: som_map.data[0].z = um.reshape(self.m,self.n)\n",
    "\n",
    "    def hithist(self, som_map=None, idata = [], color='RdBu', interp = \"best\", title=\"\"):\n",
    "        hist = self.get_hist(idata)\n",
    "        \n",
    "        if som_map==None: return self.plot(hist.reshape(self.m,self.n), color=color, interp=interp, title=title)        \n",
    "        else:  som_map.data[0].z = np.array(hist).reshape(self.m,self.n)\n",
    "\n",
    "    def component_plane(self, som_map=None, component=0, color=\"Viridis\", interp = \"best\", title=\"\"):\n",
    "        if som_map==None: return self.plot(self.weights[:,component].reshape(-1,self.n), color=color, interp=interp, title=title)   \n",
    "        else:  som_map.data[0].z = self.weights[:,component].reshape(-1,n)\n",
    "\n",
    "    def sdh(self, som_map=None, idata=[], sdh_type=1, factor=1, draw=True, color=\"Cividis\", interp = \"best\", title=\"\"):\n",
    "\n",
    "        import heapq\n",
    "        sdh_m = [0] *self.m *self.n\n",
    "\n",
    "        cs=0\n",
    "        for i in range(0,factor): cs += factor-i\n",
    "\n",
    "        for vector in idata:\n",
    "            dist = np.sqrt(np.sum(np.power(self.weights - vector, 2), axis=1))\n",
    "            c = heapq.nsmallest(factor, range(len(dist)), key=dist.__getitem__)\n",
    "            if (sdh_type==1): \n",
    "                for j in range(0,factor):  sdh_m[c[j]] += (factor-j)/cs # normalized\n",
    "            if (sdh_type==2):\n",
    "                for j in range(0,factor): sdh_m[c[j]] += 1.0/dist[c[j]] # based on distance\n",
    "            if (sdh_type==3): \n",
    "                dmin = min(dist)\n",
    "                for j in range(0,factor): sdh_m[c[j]] += 1.0 - (dist[c[j]]-dmin)/(max(dist)-dmin)  \n",
    "\n",
    "        if som_map==None: return self.plot(np.array(sdh_m).reshape(-1,self.n), color=color, interp=interp, title=title)      \n",
    "        else: som_map.data[0].z = np.array(sdh_m).reshape(-1,self.n)\n",
    "        \n",
    "    def project_data(self,som_m=None, idata=[], title=\"\"):\n",
    "\n",
    "        data_y = []\n",
    "        data_x = []\n",
    "        for v in idata:\n",
    "            position =np.argmin(np.sqrt(np.sum(np.power(self.weights - v, 2), axis=1)))\n",
    "            x,y = position % self.n, position // self.n\n",
    "            data_x.extend([x])\n",
    "            data_y.extend([y])\n",
    "            \n",
    "        if som_m!=None: som_m.add_trace(go.Scatter(x=data_x, y=data_y, mode = \"markers\", marker_color='rgba(255, 255, 255, 0.8)',))\n",
    "    \n",
    "    def time_series(self, som_m=None, idata=[], wsize=50, title=\"\"): #not tested\n",
    "             \n",
    "        data_y = []\n",
    "        data_x = [i for i in range(0,len(idata))]\n",
    "        \n",
    "        data_x2 = []\n",
    "        data_y2 = []\n",
    "        \n",
    "        qmin = np.Inf\n",
    "        qmax = 0\n",
    "        \n",
    "        step=1\n",
    "        \n",
    "        ps = []\n",
    "        for v in idata:\n",
    "            matrix = np.sqrt(np.sum(np.power(self.weights - v, 2), axis=1))\n",
    "            position = np.argmin(matrix)\n",
    "            qerror = matrix[position]\n",
    "            if qmin>qerror: qmin = qerror\n",
    "            if qmax<qerror: qmax = qerror\n",
    "            ps.append((position, qerror))\n",
    "       \n",
    "        markerc=[]    \n",
    "        for v in ps:\n",
    "            data_y.extend([v[0]])\n",
    "            rez = v[1]/qmax\n",
    " \n",
    "            markerc.append('rgba(0, 0, 0, '+str(rez)+')') \n",
    "            \n",
    "            x,y = v[0] % self.n, v[0] // self.n \n",
    "            if    x==0: y = np.random.uniform(low=y, high=y+.1)\n",
    "            elif  x==self.m-1: y = np.random.uniform(low=y-.1, high=y)\n",
    "            elif  y==0: x = np.random.uniform(low=x, high=x+.1)\n",
    "            elif  y==self.n-1: x = np.random.uniform(low=x-.1, high=x)\n",
    "            else: x,y = np.random.uniform(low=x-.1, high=x+.1), np.random.uniform(low=y-.1, high=y+.1)                           \n",
    "            \n",
    "            data_x2.extend([x])\n",
    "            data_y2.extend([y]) \n",
    "    \n",
    "        ts_plot = go.FigureWidget(go.Scatter(x=[], y=[], mode = \"markers\", marker_color=markerc, marker=dict(colorscale='Viridis', showscale=True, color=np.random.randn(500))))\n",
    "        ts_plot.update_xaxes(range=[0, wsize])       \n",
    "\n",
    "        \n",
    "        ts_plot.data[0].x, ts_plot.data[0].y = data_x, data_y\n",
    "        som_m.add_trace(go.Scatter(x=data_x2, y=data_y2, mode = \"markers\",))\n",
    "  \n",
    "        som_m.layout.height = 500\n",
    "        ts_plot.layout.height = 500\n",
    "        som_m.layout.width = 500\n",
    "        ts_plot.layout.width = 1300\n",
    "        \n",
    "        return HBox([go.FigureWidget(som_m), go.FigureWidget(ts_plot)])\n",
    "    \n",
    "    def plot(self, matrix, color=\"Viridis\", interp = \"best\", title=\"\"):\n",
    "        return go.FigureWidget(go.Heatmap(z=matrix, zsmooth=interp, showscale=False, colorscale=color), layout=go.Layout(width=700, height=700,title=title, title_x=0.5,))\n",
    "    \n",
    "    def plot_clusters(self, n_clusters: int, labels, use_mask, mask, title=\"\"):\n",
    "        matrix = labels.reshape(self.m,self.n)\n",
    "        if use_mask:\n",
    "            mask = mask.reshape(self.m, self.n)\n",
    "            matrix[~mask] = None\n",
    "        xgap = 2\n",
    "        ygap = 2\n",
    "        if n_clusters == 2:\n",
    "            color = \"Bluered\"\n",
    "        else:\n",
    "            color = \"Rainbow\"\n",
    "        return go.FigureWidget(\n",
    "            go.Heatmap(\n",
    "                z=matrix,\n",
    "                showscale=False,\n",
    "                colorscale=color,\n",
    "                xgap=xgap,\n",
    "                ygap=ygap\n",
    "            ),\n",
    "            layout=go.Layout(\n",
    "                width=700,\n",
    "                height=700,\n",
    "                title=title,\n",
    "                title_x=0.5,\n",
    "                plot_bgcolor=\"black\",\n",
    "                xaxis=dict(showgrid=False, zeroline=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False)\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def kmeans(self, n_clusters: int, idata=[], title=\"\", use_mask=True, random_state=42):\n",
    "        if use_mask:\n",
    "            mask = self.get_mask(idata)\n",
    "            weights = self.weights[mask]\n",
    "        else:\n",
    "            mask = None\n",
    "            weights = self.weights\n",
    "\n",
    "        # Train k-means classifier\n",
    "        k_means = cluster.KMeans(n_clusters=n_clusters, n_init=1, max_iter=1000, random_state=random_state).fit(weights)\n",
    "\n",
    "        if use_mask:\n",
    "            labels = np.zeros(mask.shape)\n",
    "            labels[mask] = k_means.labels_\n",
    "        else:\n",
    "            labels = k_means.labels_\n",
    "            \n",
    "        return self.plot_clusters(n_clusters, labels, use_mask=use_mask, mask=mask, title=title)\n",
    "    \n",
    "    def single_linkage(self, n_clusters: int, idata=[], title=\"\", use_mask=True):\n",
    "        if use_mask:\n",
    "            mask = self.get_mask(idata)\n",
    "            weights = self.weights[mask]\n",
    "        else:\n",
    "            mask = None\n",
    "            weights = self.weights\n",
    "    \n",
    "        # Calculate distance matrix\n",
    "        y = distance.pdist(weights)\n",
    "        # Calculate single linkage\n",
    "        Z = hierarchy.single(y)\n",
    "        \n",
    "        # Get labels of weight vector\n",
    "        # (minimum label is 1, therefore 1 must be subtracted)\n",
    "        if use_mask:\n",
    "            labels = np.zeros(mask.shape)\n",
    "            labels[mask] = hierarchy.fcluster(Z, n_clusters, criterion=\"maxclust\") - 1\n",
    "        else:\n",
    "            labels = hierarchy.fcluster(Z, n_clusters, criterion=\"maxclust\") - 1\n",
    "\n",
    "        return self.plot_clusters(n_clusters, labels, use_mask=use_mask, mask=mask, title=title)\n",
    "    \n",
    "    def complete_linkage(self, n_clusters: int, idata=[], title=\"\", use_mask=True):\n",
    "        if use_mask:\n",
    "            mask = self.get_mask(idata)\n",
    "            weights = self.weights[mask]\n",
    "        else:\n",
    "            mask = None\n",
    "            weights = self.weights\n",
    "    \n",
    "        # Calculate distance matrix\n",
    "        y = distance.pdist(weights)\n",
    "        # Calculate single linkage\n",
    "        Z = hierarchy.complete(y)\n",
    "        \n",
    "        # Get labels of weight vector\n",
    "        # (minimum label is 1, therefore 1 must be subtracted)\n",
    "        if use_mask:\n",
    "            labels = np.zeros(mask.shape)\n",
    "            labels[mask] = hierarchy.fcluster(Z, n_clusters, criterion=\"maxclust\") - 1\n",
    "        else:\n",
    "            labels = hierarchy.fcluster(Z, n_clusters, criterion=\"maxclust\") - 1\n",
    "\n",
    "        return self.plot_clusters(n_clusters, labels, use_mask=use_mask, mask=mask, title=title)\n",
    "\n",
    "    def ward(self, n_clusters: int, idata=[], title=\"\", use_mask=True):\n",
    "        if use_mask:\n",
    "            mask = self.get_mask(idata)\n",
    "            weights = self.weights[mask]\n",
    "        else:\n",
    "            mask = None\n",
    "            weights = self.weights\n",
    "    \n",
    "        # Calculate distance matrix\n",
    "        y = distance.pdist(weights)\n",
    "        # Calculate single linkage\n",
    "        Z = hierarchy.ward(y)\n",
    "        \n",
    "        # Get labels of weight vector\n",
    "        # (minimum label is 1, therefore 1 must be subtracted)\n",
    "        if use_mask:\n",
    "            labels = np.zeros(mask.shape)\n",
    "            labels[mask] = hierarchy.fcluster(Z, n_clusters, criterion=\"maxclust\") - 1\n",
    "        else:\n",
    "            labels = hierarchy.fcluster(Z, n_clusters, criterion=\"maxclust\") - 1\n",
    "\n",
    "        return self.plot_clusters(n_clusters, labels, use_mask=use_mask, mask=mask, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function can be used to load and pre-process (i.e. scale with `sklearn`'s min-max-scaling) three different datasets, namely the Iris, the Chainlink and the 10 Clusters dataset. The functions also print the `shape` of the data, thus implicitly informing us about the nature of the SOM (emergent or not, average number of datapoints per unit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, preprocessing\n",
    "\n",
    "# Get pre-precessed datasets.\n",
    "\n",
    "def get_iris():\n",
    "    iris = datasets.load_iris().data\n",
    "    print(\"Shape of the Iris data: {}\".format(iris.shape))\n",
    "    return preprocessing.MinMaxScaler().fit_transform(iris)\n",
    "\n",
    "def get_chainlink():\n",
    "    chainlink = pd.read_table(\"chainlink.vec\", sep = \" \", header = None, index_col = 3)\n",
    "    print(\"Shape of the Chainlink data: {}\".format(chainlink.shape))\n",
    "    return preprocessing.MinMaxScaler().fit_transform(chainlink)\n",
    "\n",
    "def get_ten_clusters():\n",
    "    ten_clusters = pd.read_table(\"10clusters.vec\", sep = \" \", header = None, index_col = 10)\n",
    "    print(\"Shape of the 10 Clusters data: {}\".format(ten_clusters.shape))\n",
    "    return preprocessing.MinMaxScaler().fit_transform(ten_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains the Iris dataset example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of the Iris data: (150, 4)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, '#000004'], [0.1111111111111111, '#180f3d'],\n…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b31752f02ff4c2eb9deb838ed845753"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import minisom as som\n",
    "#interp: False, 'best', 'fast', \n",
    "#color = 'viridis': https://plotly.com/python/builtin-colorscales/\n",
    "\n",
    "\n",
    "\n",
    "#############################\n",
    "######## miniSOM ############1/0\n",
    "#############################\n",
    "m=10\n",
    "n=10\n",
    "\n",
    "# Pre-processing \n",
    "iris = get_iris()\n",
    "\n",
    "# Train\n",
    "s = som.MiniSom(m, n, iris.shape[1], sigma=0.8, learning_rate=0.7)\n",
    "s.train_random(iris, 10000, verbose=False)\n",
    "\n",
    "# Visualizaton\n",
    "viz_miniSOM = SomViz(s._weights.reshape(-1,4), m, n)\n",
    "um1 = viz_miniSOM.umatrix(color='magma', interp='best', title='U-matrix miniSOM')\n",
    "\n",
    "\n",
    "##########################################\n",
    "######## read from SOMToolBox ############\n",
    "##########################################\n",
    "trainedmap = SOMToolBox_Parse('iris.norm.vec')\n",
    "idata, idim, idata_x, idata_y = trainedmap.read_weight_file()\n",
    "\n",
    "smap = SOMToolBox_Parse('iris.wgt.gz')\n",
    "smap, sdim, smap_x, smap_y = smap.read_weight_file()\n",
    "\n",
    "# Visualizaton\n",
    "viz_SOMToolBox = SomViz(smap.values.reshape(-1,sdim), smap_y, smap_x)\n",
    "# um2 = viz_SOMToolBox.umatrix(color='viridis', interp=False, title='U-matrix SOMToolBox') \n",
    "um2 = viz_SOMToolBox.umatrix(color='magma', interp='best', title='U-matrix SOMToolBox')\n",
    "\n",
    "display(HBox([um1, um2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with Java SOMToolbox\n",
    "\n",
    "For the comparison with the [Java SOMToolbox](http://www.ifs.tuwien.ac.at/dm/somtoolbox/index.html), we have decided to work with the Iris dataset and a 10x10 SOM. The SOMToolbox seems to have troubles with visualizations for the large SOMs that we have created below. Furthermore, in our opinion, the comparison on a small SOM, using a well-understood dataset, should be sufficient to validate the correct behaviour of our visualizations.\n",
    "\n",
    "The following cell showcases our four clustering visualizations on a small 10x10 SOM of the Iris dataset, of course with 3 clusters. Below, we have displayed the four corresponding visualizations produced by the SOM Toolbox, with the exception of the k-means clustering, which unfortunately did not work, as the program crashes as a consequence. With the exception of the colors, of course, we observe that the visualizations are equal, albeit mirrored along the horizontal axis. Therefore, we conclude that our clustering visualizations are correct.\n",
    "\n",
    "<table><tr><td><img src='' width=400></td><td><img src='WARD Iris.png' width=400></td></tr></table>\n",
    "<table><tr><td><img src='Single Linkage Iris.png' width=400></td><td><img src='Complete Linkage Iris.png' width=400></td></tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, 'rgb(150,0,90)'], [0.125, 'rgb(0,0,200)'],\n  …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06209a25b9314efbb95f63b53b057903"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, 'rgb(150,0,90)'], [0.125, 'rgb(0,0,200)'],\n  …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3bea2264cba946539c46d9724264483f"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "m=10\n",
    "n=10\n",
    "\n",
    "trainedmap = SOMToolBox_Parse('iris.norm.vec')\n",
    "idata, idim, idata_x, idata_y = trainedmap.read_weight_file()\n",
    "\n",
    "smap = SOMToolBox_Parse('iris.wgt.gz')\n",
    "smap, sdim, smap_x, smap_y = smap.read_weight_file()\n",
    "\n",
    "# Visualization\n",
    "viz = SomViz(smap.values.reshape(-1,sdim), smap_y, smap_x)\n",
    "n_clusters = 3\n",
    "\n",
    "viz_kmeans = viz.kmeans(n_clusters, idata=idata, title=f\"k-means - Iris ({m}x{n})\", use_mask=False)\n",
    "viz_ward = viz.ward(n_clusters, idata=idata, title=f\"WARD - Iris ({m}x{n})\", use_mask=False)\n",
    "\n",
    "viz_single = viz.single_linkage(n_clusters, idata=idata, title=f\"Single linkage - Iris ({m}x{n})\", use_mask=False)\n",
    "viz_complete = viz.complete_linkage(n_clusters, idata=idata, title=f\"Complete linkage - Iris ({m}x{n})\", use_mask=False)\n",
    "\n",
    "display(HBox([viz_kmeans, viz_ward]))\n",
    "display(HBox([viz_single, viz_complete]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically for the task of producing clustering visualizations, we wrote the `SOMWrapper` class. It can be initialized with the SOM-specific parameters (size m x n, sigma, learning rate) as well as the number of clusters to produce in the visualizations. The class also contains a `train()` function which trains the SOM (for 10000 iterations by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minisom import MiniSom\n",
    "\n",
    "class SOMWrapper:\n",
    "    def __init__(self, name=\"\", data=[], m=10, n=10, n_clusters=3, sigma=1.0, learning_rate=0.7):\n",
    "        self.name = name\n",
    "        self.data = data\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.n_clusters = n_clusters\n",
    "        self.sigma = sigma\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.som = MiniSom(m, n, data.shape[1], sigma=sigma, learning_rate=learning_rate)\n",
    "    \n",
    "    def train(self, num_iterations=10000, verbose=False):\n",
    "        self.som.train_random(self.data, num_iterations, verbose=verbose)\n",
    "        self.viz = SomViz(self.som._weights.reshape(-1, self.data.shape[-1]), self.m, self.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell we create two SOM's for the Chainlink dataset. A small SOM (40x20, 800 units) and a large SOM (100x60, 6000 units). We use a sigma of 2.0 and a learning rate of 0.07. Each SOM is trained for 10000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of the Chainlink data: (1000, 3)\nShape of the Chainlink data: (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Train SOMs on chainlink dataset\n",
    "#\n",
    "\n",
    "soms_chainlink = [\n",
    "    # Small SOM\n",
    "    SOMWrapper(\n",
    "        name=\"Chainlink\",\n",
    "        data=get_chainlink(),\n",
    "        m=40,\n",
    "        n=20,\n",
    "        n_clusters=2,\n",
    "        sigma=2,\n",
    "        learning_rate=0.07\n",
    "    ),\n",
    "    # Large SOM\n",
    "    SOMWrapper(\n",
    "        name=\"Chainlink\",\n",
    "        data=get_chainlink(),\n",
    "        m=100,\n",
    "        n=60,\n",
    "        n_clusters=2,\n",
    "        sigma=2,\n",
    "        learning_rate=0.07,\n",
    "    )\n",
    "]\n",
    "\n",
    "for som in soms_chainlink:\n",
    "    som.train(num_iterations=10_000, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the visualizations for both the small and the large SOM on the Chainlink dataset. Aside from the four different clustering visualizations that we implemented, we also show a Hit-histogram and a U-matrix visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, 'rgb(103,0,31)'], [0.1, 'rgb(178,24,43)'],\n  …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "438c56b8990e423fae7f0ba2a3870a8a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, 'rgb(0,0,255)'], [1.0, 'rgb(255,0,0)']],\n    …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4396f1fbf4ea45228c1856c07765d166"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, 'rgb(0,0,255)'], [1.0, 'rgb(255,0,0)']],\n    …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f57945a0e1dd4be099c403e9432786fd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, 'rgb(103,0,31)'], [0.1, 'rgb(178,24,43)'],\n  …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d1c4003395b44b72ae45ea09ed2d1178"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, 'rgb(0,0,255)'], [1.0, 'rgb(255,0,0)']],\n    …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68973056159f4c4fa56bdd22d88a7b40"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, 'rgb(0,0,255)'], [1.0, 'rgb(255,0,0)']],\n    …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "25f0322921ed496ca4b9f173661038dc"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "#\n",
    "# Visualizations on chainlink dataset\n",
    "#\n",
    "from ipywidgets import HBox, VBox\n",
    "import random\n",
    "\n",
    "for som in soms_chainlink:\n",
    "    \n",
    "    viz_hit = som.viz.hithist(idata=som.data, interp=False, title=f\"Hit-histogram - {som.name} ({som.m}x{som.n})\")\n",
    "    viz_um = som.viz.umatrix(color='viridis', interp=False, title=f\"U-matrix - {som.name} ({som.m}x{som.n})\")\n",
    "\n",
    "    viz_kmeans = som.viz.kmeans(som.n_clusters, idata=som.data, title=f\"k-means - {som.name} ({som.m}x{som.n})\")\n",
    "    viz_ward = som.viz.ward(som.n_clusters, idata=som.data, title=f\"WARD - {som.name} ({som.m}x{som.n})\")\n",
    "\n",
    "    viz_single = som.viz.single_linkage(som.n_clusters, idata=som.data, title=f\"Single linkage - {som.name} ({som.m}x{som.n})\")\n",
    "    viz_complete = som.viz.complete_linkage(som.n_clusters, idata=som.data, title=f\"Complete linkage - {som.name} ({som.m}x{som.n})\")\n",
    "\n",
    "    display(HBox([viz_hit, viz_um]))\n",
    "    display(HBox([viz_kmeans, viz_ward]))\n",
    "    display(HBox([viz_single, viz_complete]))"
   ]
  },
  {
   "source": [
    "To ensure that the chosen parameters for our SOMs for the chainlink dataset are appropriate, we train additional SOMs with some extreme values for sigma and the learning rate."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of the Chainlink data: (1000, 3)\nShape of the Chainlink data: (1000, 3)\nShape of the Chainlink data: (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "soms_chainlink_extreme = [\n",
    "    SOMWrapper(\n",
    "        name=\"Chainlink\",\n",
    "        data=get_chainlink(),\n",
    "        m=40,\n",
    "        n=20,\n",
    "        n_clusters=2,\n",
    "        sigma=0.01,\n",
    "        learning_rate=0.01,\n",
    "    ),\n",
    "    SOMWrapper(\n",
    "        name=\"Chainlink\",\n",
    "        data=get_chainlink(),\n",
    "        m=40,\n",
    "        n=20,\n",
    "        n_clusters=2,\n",
    "        sigma=10,\n",
    "        learning_rate=10,\n",
    "    ),\n",
    "    SOMWrapper(\n",
    "        name=\"Chainlink\",\n",
    "        data=get_chainlink(),\n",
    "        m=40,\n",
    "        n=20,\n",
    "        n_clusters=2,\n",
    "        sigma=1,\n",
    "        learning_rate=0.5,\n",
    "    ),\n",
    "]\n",
    "\n",
    "for som in soms_chainlink_extreme:\n",
    "    som.train(num_iterations=10_000, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, 'rgb(103,0,31)'], [0.1, 'rgb(178,24,43)'],\n  …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f560a9b492649baae65e1854f76620c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, 'rgb(103,0,31)'], [0.1, 'rgb(178,24,43)'],\n  …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b668875c1b4e497b8b54caaee5626abd"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "from ipywidgets import HBox, VBox\n",
    "\n",
    "som_normal = soms_chainlink[0]\n",
    "som_ext1 = soms_chainlink_extreme[0]\n",
    "som_ext2 = soms_chainlink_extreme[1]\n",
    "som_ext3 = soms_chainlink_extreme[2]\n",
    "\n",
    "viz_normal = som_normal.viz.hithist(idata=som_normal.data, interp=False, title=f\"{som_normal.name}: sigma={som_normal.sigma}, lr={som_normal.learning_rate}\")\n",
    "viz_ext1 = som_ext1.viz.hithist(idata=som_ext1.data, interp=False, title=f\"{som_ext1.name}: sigma={som_ext1.sigma}, lr={som_ext1.learning_rate}\")\n",
    "viz_ext2 = som_ext2.viz.hithist(idata=som_ext2.data, interp=False, title=f\"{som_ext2.name}: sigma={som_ext2.sigma}, lr={som_ext2.learning_rate}\")\n",
    "viz_ext3 = som_ext3.viz.hithist(idata=som_ext3.data, interp=False, title=f\"{som_ext3.name}: sigma={som_ext3.sigma}, lr={som_ext3.learning_rate}\")\n",
    "\n",
    "display(HBox([viz_normal, viz_ext1]))\n",
    "display(HBox([viz_ext2, viz_ext3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell we create two SOM's for the 10-clusters dataset. A small SOM (40x20, 800 units) and a large SOM (100x60, 6000 units). We use a sigma of 2.0 and a learning rate of 0.07. Each SOM is trained for 10000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of the 10 Clusters data: (850, 10)\nShape of the 10 Clusters data: (850, 10)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Train SOMs on 10-clusters dataset\n",
    "#\n",
    "\n",
    "soms_ten_clusters = [\n",
    "    SOMWrapper(\n",
    "        name=\"10-clusters\",\n",
    "        data=get_ten_clusters(),\n",
    "        m=40,\n",
    "        n=20,\n",
    "        n_clusters=10,\n",
    "        sigma=2,\n",
    "        learning_rate=0.07,\n",
    "    ),\n",
    "    SOMWrapper(\n",
    "        name=\"10-clusters\",\n",
    "        data=get_ten_clusters(),\n",
    "        m=100,\n",
    "        n=60,\n",
    "        n_clusters=10,\n",
    "        sigma=2,\n",
    "        learning_rate=0.07,\n",
    "    ),\n",
    "]\n",
    "\n",
    "for som in soms_ten_clusters:\n",
    "    som.train(num_iterations=10_000, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the visualizations for both the small and the large SOM on the 10 clusters dataset. Aside from the four different clustering visualizations that we implemented, we also show a Hit-histogram and a U-matrix visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, 'rgb(103,0,31)'], [0.1, 'rgb(178,24,43)'],\n  …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc4ea08fd509482c9fc458552fa776a0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, 'rgb(150,0,90)'], [0.125, 'rgb(0,0,200)'],\n  …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cec3601da8474008b999120b4ca352bd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, 'rgb(150,0,90)'], [0.125, 'rgb(0,0,200)'],\n  …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "552b1e5da1c4405f803cc716f9d8c14f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, 'rgb(103,0,31)'], [0.1, 'rgb(178,24,43)'],\n  …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10eb6102c2a44218b37a1db534f65a70"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, 'rgb(150,0,90)'], [0.125, 'rgb(0,0,200)'],\n  …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5ec4104a02a4b1b8778b95a30735381"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, 'rgb(150,0,90)'], [0.125, 'rgb(0,0,200)'],\n  …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddc8b9e610e540b2bafe4c385355f23a"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "#\n",
    "# Visualizations on 10-clusters dataset\n",
    "#\n",
    "from ipywidgets import HBox, VBox\n",
    "\n",
    "for som in soms_ten_clusters:\n",
    "\n",
    "    viz_hit = som.viz.hithist(idata=som.data, interp=False, title=f\"Hit-histogram - {som.name} ({som.m}x{som.n})\")\n",
    "    viz_um  = som.viz.umatrix(color='viridis', interp=False, title=f\"U-matrix - {som.name} ({som.m}x{som.n})\")\n",
    "\n",
    "    viz_kmeans = som.viz.kmeans(som.n_clusters, idata=som.data, title=f\"k-means - {som.name} ({som.m}x{som.n})\")\n",
    "    viz_ward   = som.viz.ward(som.n_clusters, idata=som.data, title=f\"WARD - {som.name} ({som.m}x{som.n})\")\n",
    "\n",
    "    viz_single = som.viz.single_linkage(som.n_clusters, idata=som.data, title=f\"Single linkage - {som.name} ({som.m}x{som.n}))\")\n",
    "    viz_complete = som.viz.complete_linkage(som.n_clusters, idata=som.data, title=f\"Complete linkage - {som.name} ({som.m}x{som.n})\")\n",
    "\n",
    "    display(HBox([viz_hit, viz_um]))\n",
    "    display(HBox([viz_kmeans, viz_ward]))\n",
    "    display(HBox([viz_single, viz_complete]))"
   ]
  },
  {
   "source": [
    "One interesting observation about the clustering of the 10-clusters dataset is that none of the clustering algorithms is able to properly separate the 10 clusters. Although humans may be able to spot the ten different clusters, the algorithms seem to have problems with it. We assume that this is caused be the non-convex mapping of the data to the SOM."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "To ensure that the chosen parameters for our SOMs for the 10-clusters dataset are appropriate, we train additional SOMs with some extreme values for sigma and the learning rate."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of the 10 Clusters data: (850, 10)\nShape of the 10 Clusters data: (850, 10)\nShape of the 10 Clusters data: (850, 10)\n"
     ]
    }
   ],
   "source": [
    "soms_ten_clusters_extreme = [\n",
    "    SOMWrapper(\n",
    "        name=\"10-clusters\",\n",
    "        data=get_ten_clusters(),\n",
    "        m=40,\n",
    "        n=20,\n",
    "        n_clusters=10,\n",
    "        sigma=0.01,\n",
    "        learning_rate=0.01,\n",
    "    ),\n",
    "    SOMWrapper(\n",
    "        name=\"10-clusters\",\n",
    "        data=get_ten_clusters(),\n",
    "        m=40,\n",
    "        n=20,\n",
    "        n_clusters=10,\n",
    "        sigma=10,\n",
    "        learning_rate=10,\n",
    "    ),\n",
    "    SOMWrapper(\n",
    "        name=\"10-clusters\",\n",
    "        data=get_ten_clusters(),\n",
    "        m=40,\n",
    "        n=20,\n",
    "        n_clusters=10,\n",
    "        sigma=1,\n",
    "        learning_rate=0.5,\n",
    "    ),\n",
    "]\n",
    "\n",
    "for som in soms_ten_clusters_extreme:\n",
    "    som.train(num_iterations=10_000, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, 'rgb(103,0,31)'], [0.1, 'rgb(178,24,43)'],\n  …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e442eeb672c14ddda3d9dd15e9368a21"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FigureWidget({\n    'data': [{'colorscale': [[0.0, 'rgb(103,0,31)'], [0.1, 'rgb(178,24,43)'],\n  …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64f444fd2e164422bfb1ad3fd44bf8af"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "from ipywidgets import HBox, VBox\n",
    "\n",
    "som_normal = soms_ten_clusters[0]\n",
    "som_ext1 = soms_ten_clusters_extreme[0]\n",
    "som_ext2 = soms_ten_clusters_extreme[1]\n",
    "som_ext3 = soms_ten_clusters_extreme[2]\n",
    "\n",
    "viz_normal = som_normal.viz.hithist(idata=som_normal.data, interp=False, title=f\"{som_normal.name}: sigma={som_normal.sigma}, lr={som_normal.learning_rate}\")\n",
    "viz_ext1 = som_ext1.viz.hithist(idata=som_ext1.data, interp=False, title=f\"{som_ext1.name}: sigma={som_ext1.sigma}, lr={som_ext1.learning_rate}\")\n",
    "viz_ext2 = som_ext2.viz.hithist(idata=som_ext2.data, interp=False, title=f\"{som_ext2.name}: sigma={som_ext2.sigma}, lr={som_ext2.learning_rate}\")\n",
    "viz_ext3 = som_ext3.viz.hithist(idata=som_ext3.data, interp=False, title=f\"{som_ext3.name}: sigma={som_ext3.sigma}, lr={som_ext3.learning_rate}\")\n",
    "\n",
    "display(HBox([viz_normal, viz_ext1]))\n",
    "display(HBox([viz_ext2, viz_ext3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}